{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T05:34:16.961957Z",
     "iopub.status.busy": "2022-04-11T05:34:16.96154Z",
     "iopub.status.idle": "2022-04-11T05:34:26.548202Z",
     "shell.execute_reply": "2022-04-11T05:34:26.546815Z",
     "shell.execute_reply.started": "2022-04-11T05:34:16.961896Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-11T05:34:29.409094Z",
     "iopub.status.busy": "2022-04-11T05:34:29.408702Z",
     "iopub.status.idle": "2022-04-11T05:34:29.442586Z",
     "shell.execute_reply": "2022-04-11T05:34:29.441384Z",
     "shell.execute_reply.started": "2022-04-11T05:34:29.409027Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:40:44.168959Z",
     "iopub.status.busy": "2022-04-09T11:40:44.16847Z",
     "iopub.status.idle": "2022-04-09T11:40:44.574387Z",
     "shell.execute_reply": "2022-04-09T11:40:44.568823Z",
     "shell.execute_reply.started": "2022-04-09T11:40:44.1689Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/understanding_cloud_organization')\n",
    "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.575196Z",
     "iopub.status.idle": "2022-04-09T11:40:44.575897Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
    "print(mask_count_df.shape)\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.577456Z",
     "iopub.status.idle": "2022-04-09T11:40:44.577888Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "Source: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "\n",
    "Unhide below for the definition of `np_resize`, `build_masks`, `build_rles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.58026Z",
     "iopub.status.idle": "2022-04-09T11:40:44.580883Z"
    }
   },
   "outputs": [],
   "source": [
    "def np_resize(img, input_shape):\n",
    "    \"\"\"\n",
    "    Reshape a numpy array, which is input_shape=(height, width), \n",
    "    as opposed to input_shape=(width, height) for cv2\n",
    "    \"\"\"\n",
    "    height, width = input_shape\n",
    "    return cv2.resize(img, (width, height))\n",
    "    \n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape, reshape=None):\n",
    "    depth = len(rles)\n",
    "    if reshape is None:\n",
    "        masks = np.zeros((*input_shape, depth))\n",
    "    else:\n",
    "        masks = np.zeros((*reshape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            if reshape is None:\n",
    "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "            else:\n",
    "                mask = rle2mask(rle, input_shape)\n",
    "                reshaped_mask = np_resize(mask, reshape)\n",
    "                masks[:, :, i] = reshaped_mask\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks, reshape=None):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        if reshape:\n",
    "            mask = mask.astype(np.float32)\n",
    "            mask = np_resize(mask, reshape).astype(np.int64)\n",
    "        \n",
    "        rle = mask2rle(mask)\n",
    "        rles.append(rle)\n",
    "        \n",
    "    return rles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAdam\n",
    "\n",
    "Unhide below to see definition of `RAdam`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.582037Z",
     "iopub.status.idle": "2022-04-09T11:40:44.582653Z"
    }
   },
   "outputs": [],
   "source": [
    "class RAdam(keras.optimizers.Optimizer):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay for each param.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n",
    "        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n",
    "        min_lr: float >= 0. Minimum learning rate after warmup.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n",
    "                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n",
    "        super(RAdam, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.total_steps = K.variable(total_steps, name='total_steps')\n",
    "            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.initial_weight_decay = weight_decay\n",
    "        self.initial_total_steps = total_steps\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        if self.initial_total_steps > 0:\n",
    "            warmup_steps = self.total_steps * self.warmup_proportion\n",
    "            lr = K.switch(\n",
    "                t <= warmup_steps,\n",
    "                lr * (t / warmup_steps),\n",
    "                self.min_lr + (lr - self.min_lr) * (1.0 - K.minimum(t, self.total_steps) / self.total_steps),\n",
    "            )\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n",
    "        else:\n",
    "            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n",
    "\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        beta_1_t = K.pow(self.beta_1, t)\n",
    "        beta_2_t = K.pow(self.beta_2, t)\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            m_corr_t = m_t / (1.0 - beta_1_t)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t) + self.epsilon)\n",
    "\n",
    "            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                         (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                         sma_inf / sma_t)\n",
    "\n",
    "            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / v_corr_t, m_corr_t)\n",
    "\n",
    "            if self.initial_weight_decay > 0:\n",
    "                p_t += self.weight_decay * p\n",
    "\n",
    "            p_t = p - lr * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'lr': float(K.get_value(self.lr)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'decay': float(K.get_value(self.decay)),\n",
    "            'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': float(K.get_value(self.total_steps)),\n",
    "            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "        }\n",
    "        base_config = super(RAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "Source for `bce_dice_loss`: https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.583727Z",
     "iopub.status.idle": "2022-04-09T11:40:44.584298Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide below for the definition of `DataGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.585429Z",
     "iopub.status.idle": "2022-04-09T11:40:44.586022Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path='../input/train_images',\n",
    "                 batch_size=32, dim=(1400, 2100), n_channels=3, reshape=None,\n",
    "                 augment=False, n_classes=4, random_state=2019, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.reshape = reshape\n",
    "        self.n_channels = n_channels\n",
    "        self.augment = augment\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            \n",
    "            if self.augment:\n",
    "                X, y = self.__augment_batch(X, y)\n",
    "            \n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        if self.reshape is None:\n",
    "            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        else:\n",
    "            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_rgb(img_path)\n",
    "            \n",
    "            if self.reshape is not None:\n",
    "                img = np_resize(img, self.reshape)\n",
    "            \n",
    "            # Store samples\n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        if self.reshape is None:\n",
    "            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        else:\n",
    "            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            \n",
    "            if self.reshape is not None:\n",
    "                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n",
    "            else:\n",
    "                masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __random_transform(self, img, masks):\n",
    "        composition = albu.Compose([\n",
    "            albu.HorizontalFlip(),\n",
    "            albu.VerticalFlip(),\n",
    "            albu.ShiftScaleRotate(rotate_limit=45, shift_limit=0.15, scale_limit=0.15)\n",
    "        ])\n",
    "        \n",
    "        composed = composition(image=img, mask=masks)\n",
    "        aug_img = composed['image']\n",
    "        aug_masks = composed['mask']\n",
    "        \n",
    "        return aug_img, aug_masks\n",
    "    \n",
    "    def __augment_batch(self, img_batch, masks_batch):\n",
    "        for i in range(img_batch.shape[0]):\n",
    "            img_batch[i, ], masks_batch[i, ] = self.__random_transform(\n",
    "                img_batch[i, ], masks_batch[i, ])\n",
    "        \n",
    "        return img_batch, masks_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide below for the old architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.587124Z",
     "iopub.status.idle": "2022-04-09T11:40:44.587725Z"
    }
   },
   "outputs": [],
   "source": [
    "def vanilla_unet(input_shape):\n",
    "    \"\"\"\n",
    "    This is the old model. Best LB is ~0.5\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
    "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2), padding='same') (c1)\n",
    "\n",
    "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
    "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2), padding='same') (c2)\n",
    "\n",
    "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
    "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2), padding='same') (c3)\n",
    "\n",
    "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
    "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
    "    p4 = MaxPooling2D((2, 2), padding='same') (c4)\n",
    "\n",
    "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
    "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
    "    p5 = MaxPooling2D((2, 2), padding='same') (c5)\n",
    "\n",
    "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
    "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
    "\n",
    "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
    "    u6 = concatenate([u6, c5])\n",
    "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
    "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
    "\n",
    "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u71 = concatenate([u71, c4])\n",
    "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
    "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
    "\n",
    "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
    "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
    "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.588794Z",
     "iopub.status.idle": "2022-04-09T11:40:44.58937Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    mask_count_df.index, random_state=2019, test_size=0.2\n",
    ")\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    reshape=(320, 480),\n",
    "    augment=True,\n",
    "    n_channels=3,\n",
    "    n_classes=4\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    reshape=(320, 480),\n",
    "    augment=False,\n",
    "    n_channels=3,\n",
    "    n_classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide below for summary of model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.590446Z",
     "iopub.status.idle": "2022-04-09T11:40:44.591036Z"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.Unet(\n",
    "    'resnet34', \n",
    "    classes=4,\n",
    "    input_shape=(320, 480, 3),\n",
    "    activation='sigmoid'\n",
    ")\n",
    "model.compile(optimizer=Nadam(lr=0.0002), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide below for training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.592086Z",
     "iopub.status.idle": "2022-04-09T11:40:44.592691Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.593785Z",
     "iopub.status.idle": "2022-04-09T11:40:44.594365Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['dice_coef', 'val_dice_coef']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.595475Z",
     "iopub.status.idle": "2022-04-09T11:40:44.596094Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "test_df = []\n",
    "\n",
    "for i in range(0, test_imgs.shape[0], 500):\n",
    "    batch_idx = list(\n",
    "        range(i, min(test_imgs.shape[0], i + 500))\n",
    "    )\n",
    "\n",
    "    test_generator = DataGenerator(\n",
    "        batch_idx,\n",
    "        df=test_imgs,\n",
    "        shuffle=False,\n",
    "        mode='predict',\n",
    "        dim=(350, 525),\n",
    "        reshape=(320, 480),\n",
    "        n_channels=3,\n",
    "        base_path='../input/test_images',\n",
    "        target_df=sub_df,\n",
    "        batch_size=1,\n",
    "        n_classes=4\n",
    "    )\n",
    "\n",
    "    batch_pred_masks = model.predict_generator(\n",
    "        test_generator, \n",
    "        workers=1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    for j, b in enumerate(batch_idx):\n",
    "        filename = test_imgs['ImageId'].iloc[b]\n",
    "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "\n",
    "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "        pred_rles = build_rles(pred_masks, reshape=(350, 525))\n",
    "\n",
    "        image_df['EncodedPixels'] = pred_rles\n",
    "        test_df.append(image_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.59719Z",
     "iopub.status.idle": "2022-04-09T11:40:44.59779Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat(test_df)\n",
    "test_df.drop(columns='ImageId', inplace=True)\n",
    "test_df.to_csv('flower_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.598842Z",
     "iopub.status.idle": "2022-04-09T11:40:44.599424Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.600475Z",
     "iopub.status.idle": "2022-04-09T11:40:44.601061Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.602111Z",
     "iopub.status.idle": "2022-04-09T11:40:44.602711Z"
    }
   },
   "outputs": [],
   "source": [
    "filelist_trainx = sorted(glob.glob('../input/ph2-resized/trainx/*.bmp'), key=numericalSort)\n",
    "X_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainx])\n",
    "\n",
    "filelist_trainy = sorted(glob.glob('../input/ph2-resized/trainy/*.bmp'), key=numericalSort)\n",
    "Y_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.603749Z",
     "iopub.status.idle": "2022-04-09T11:40:44.604319Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.605365Z",
     "iopub.status.idle": "2022-04-09T11:40:44.605962Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(X_train[0])\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(X_train[3])\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(X_train[54])\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(X_train[77])\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow(X_train[100])\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow(X_train[125])\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(X_train[130])\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(X_train[149])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.607018Z",
     "iopub.status.idle": "2022-04-09T11:40:44.607608Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(Y_train[0], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(Y_train[3], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(Y_train[54], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(Y_train[77], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow(Y_train[100], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow(Y_train[125], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(Y_train[130], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(Y_train[149], cmap = plt.cm.binary_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.60868Z",
     "iopub.status.idle": "2022-04-09T11:40:44.60925Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.610303Z",
     "iopub.status.idle": "2022-04-09T11:40:44.610904Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth = 100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.611953Z",
     "iopub.status.idle": "2022-04-09T11:40:44.612536Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 100):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.613594Z",
     "iopub.status.idle": "2022-04-09T11:40:44.614177Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.615232Z",
     "iopub.status.idle": "2022-04-09T11:40:44.615905Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.617024Z",
     "iopub.status.idle": "2022-04-09T11:40:44.617606Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Calculates the mean accuracy rate across all predictions for binary\n",
    "    classification problems.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.618693Z",
     "iopub.status.idle": "2022-04-09T11:40:44.619264Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(x_image, y_image):\n",
    "    rows_x,cols_x, chl_x = x_image.shape\n",
    "    rows_y,cols_y = y_image.shape\n",
    "    rand_num = np.random.randint(-40,40)\n",
    "    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n",
    "    return x_image, y_image.astype('int')\n",
    "\n",
    "def horizontal_flip(x_image, y_image):\n",
    "    x_image = cv2.flip(x_image, 1)\n",
    "    y_image = cv2.flip(y_image.astype('float32'), 1)\n",
    "    return x_image, y_image.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.620319Z",
     "iopub.status.idle": "2022-04-09T11:40:44.620917Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_augmentation(x_train, y_train):\n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    x_nois = []\n",
    "    for idx in range(len(x_train)):\n",
    "        x,y = random_rotation(x_train[idx], y_train[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        \n",
    "        x,y = horizontal_flip(x_train[idx], y_train[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.621976Z",
     "iopub.status.idle": "2022-04-09T11:40:44.62257Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_augmentation(x_test, y_test):\n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    x_nois = []\n",
    "    for idx in range(len(x_test)):\n",
    "        x,y = random_rotation(x_test[idx], y_test[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        \n",
    "        x,y = horizontal_flip(x_test[idx], y_test[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "\n",
    "    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.623632Z",
     "iopub.status.idle": "2022-04-09T11:40:44.624229Z"
    }
   },
   "outputs": [],
   "source": [
    "x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)\n",
    "x_rotated_t, y_rotated_t, x_flipped_t, y_flipped_t = img_augmentation(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.625282Z",
     "iopub.status.idle": "2022-04-09T11:40:44.625876Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 114\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(x_train[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(y_train[img_num], plt.cm.binary_r)\n",
    "plt.title('Original Mask')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(x_rotated[img_num])\n",
    "plt.title('Rotated Image')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(y_rotated[img_num], plt.cm.binary_r)\n",
    "plt.title('Rotated Mask')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(x_flipped[img_num])\n",
    "plt.title('Flipped Image')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(y_flipped[img_num], plt.cm.binary_r)\n",
    "plt.title('Flipped Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.62693Z",
     "iopub.status.idle": "2022-04-09T11:40:44.627509Z"
    }
   },
   "outputs": [],
   "source": [
    "# For training Set\n",
    "x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "y_train_full = np.concatenate([y_train, y_rotated, y_flipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.628566Z",
     "iopub.status.idle": "2022-04-09T11:40:44.629159Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.630209Z",
     "iopub.status.idle": "2022-04-09T11:40:44.630805Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Length of the Training Set   : {}\".format(len(x_train)))\n",
    "print(\"Length of the Test Set       : {}\".format(len(x_test)))\n",
    "print(\"Length of the Validation Set : {}\".format(len(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.631881Z",
     "iopub.status.idle": "2022-04-09T11:40:44.632471Z"
    }
   },
   "outputs": [],
   "source": [
    "def fcn_net(epochs_num,savename):\n",
    "\n",
    "    # Convolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "    img_input = Input(shape= (192, 256, 3))\n",
    "    x = Conv2D(16, (5, 5), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(64, (4, 4), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (4, 4), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv5')(x)\n",
    "    x = BatchNormalization(name='bn5')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "\n",
    "    # Deconvolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv1')(x)\n",
    "    x = BatchNormalization(name='bn6')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv2')(x)\n",
    "    x = BatchNormalization(name='bn7')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv3')(x)\n",
    "    x = BatchNormalization(name='bn8')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv4')(x)\n",
    "    x = BatchNormalization(name='bn9')(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    pred = Reshape((192,256))(x)\n",
    "    \n",
    "    model = Model(inputs=img_input, outputs=pred)\n",
    "    \n",
    "    model.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n",
    "                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n",
    "\n",
    "    model.save(savename)\n",
    "    return model,hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.63352Z",
     "iopub.status.idle": "2022-04-09T11:40:44.634105Z"
    }
   },
   "outputs": [],
   "source": [
    "model, hist = fcn_net(epochs_num= 1, savename= 'fcn_1_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.635164Z",
     "iopub.status.idle": "2022-04-09T11:40:44.635815Z"
    }
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape= (192, 256, 3))\n",
    "x = Conv2D(16, (5, 5), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "x = BatchNormalization(name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n",
    "x = BatchNormalization(name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (4, 4), padding='same', name='conv3')(x)\n",
    "x = BatchNormalization(name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4), padding='same', name='conv4')(x)\n",
    "x = BatchNormalization(name='bn4')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), padding='same', name='conv5')(x)\n",
    "x = BatchNormalization(name='bn5')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "\n",
    "# Deconvolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv1')(x)\n",
    "x = BatchNormalization(name='bn6')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D()(x)\n",
    "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv2')(x)\n",
    "x = BatchNormalization(name='bn7')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv3')(x)\n",
    "x = BatchNormalization(name='bn8')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D()(x)\n",
    "x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv4')(x)\n",
    "x = BatchNormalization(name='bn9')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Activation('sigmoid')(x)\n",
    "pred = Reshape((192,256))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.637025Z",
     "iopub.status.idle": "2022-04-09T11:40:44.637663Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0 = Model(inputs=img_input, outputs=pred)\n",
    "model_0.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance], metrics=[iou, dice_coef, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.638713Z",
     "iopub.status.idle": "2022-04-09T11:40:44.639285Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0.load_weights('fcn_1_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.64035Z",
     "iopub.status.idle": "2022-04-09T11:40:44.640943Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n~~~~~~~~~~~~~~~Stats after 1 epoch~~~~~~~~~~~~~~~~~~~')\n",
    "print('\\n-------------On Train Set--------------------------\\n')\n",
    "res = model_0.evaluate(x_train, y_train, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On Test  Set--------------------------\\n')\n",
    "res = model_0.evaluate(x_test, y_test, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On validation Set---------------------\\n')\n",
    "res = model_0.evaluate(x_val, y_val, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.641997Z",
     "iopub.status.idle": "2022-04-09T11:40:44.642582Z"
    }
   },
   "outputs": [],
   "source": [
    "model, hist = fcn_net(epochs_num= 100, savename= 'fcn_100_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.643627Z",
     "iopub.status.idle": "2022-04-09T11:40:44.64421Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = Model(inputs=img_input, outputs=pred)\n",
    "model_1.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance], metrics=[iou, dice_coef, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.645256Z",
     "iopub.status.idle": "2022-04-09T11:40:44.645992Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1.load_weights('fcn_100_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.647082Z",
     "iopub.status.idle": "2022-04-09T11:40:44.647691Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\n",
    "print('\\n-------------On Train Set--------------------------\\n')\n",
    "res = model_1.evaluate(x_train, y_train, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On Test  Set--------------------------\\n')\n",
    "res = model_1.evaluate(x_test, y_test, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On validation Set---------------------\\n')\n",
    "res = model_1.evaluate(x_val, y_val, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.648751Z",
     "iopub.status.idle": "2022-04-09T11:40:44.649322Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14))\n",
    "plt.suptitle('Training Statistics on Train Set')\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(hist.history['loss'], 'red')\n",
    "plt.title('Loss')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(hist.history['accuracy'], 'green')\n",
    "plt.title('Accuracy')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(hist.history['val_loss'], 'red')\n",
    "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
    "plt.title('Valdiation Loss')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(hist.history['val_accuracy'], 'green')\n",
    "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
    "plt.title('Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.650376Z",
     "iopub.status.idle": "2022-04-09T11:40:44.650967Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 49\n",
    "img_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x_test[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(y_test[img_num], plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\n",
    "plt.title('Predicted Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.652021Z",
     "iopub.status.idle": "2022-04-09T11:40:44.652602Z"
    }
   },
   "outputs": [],
   "source": [
    "def enhance(img):\n",
    "    sub = (model_1.predict(img.reshape(1,192,256,3))).flatten()\n",
    "\n",
    "    for i in range(len(sub)):\n",
    "        if sub[i] > 0.5:\n",
    "            sub[i] = 1\n",
    "        else:\n",
    "            sub[i] = 0\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.653666Z",
     "iopub.status.idle": "2022-04-09T11:40:44.654234Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.suptitle('Comparing the Prediction after enhancement')\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(y_test[21],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(y_test[47],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(enhance(x_test[47]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(y_test[36],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(enhance(x_test[36]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:18:40.903061Z",
     "iopub.status.busy": "2022-04-11T06:18:40.902779Z",
     "iopub.status.idle": "2022-04-11T06:18:44.144181Z",
     "shell.execute_reply": "2022-04-11T06:18:44.143268Z",
     "shell.execute_reply.started": "2022-04-11T06:18:40.903011Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dense, BatchNormalization, concatenate, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.core import SpatialDropout2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:18:48.212131Z",
     "iopub.status.busy": "2022-04-11T06:18:48.211783Z",
     "iopub.status.idle": "2022-04-11T06:18:48.218221Z",
     "shell.execute_reply": "2022-04-11T06:18:48.217451Z",
     "shell.execute_reply.started": "2022-04-11T06:18:48.21205Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:18:53.974985Z",
     "iopub.status.busy": "2022-04-11T06:18:53.974512Z",
     "iopub.status.idle": "2022-04-11T06:18:55.522056Z",
     "shell.execute_reply": "2022-04-11T06:18:55.52131Z",
     "shell.execute_reply.started": "2022-04-11T06:18:53.974922Z"
    }
   },
   "outputs": [],
   "source": [
    "filelist_trainx = sorted(glob.glob('../input/ph2-resized/trainx/*.bmp'), key=numericalSort)\n",
    "X_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainx])\n",
    "\n",
    "filelist_trainy = sorted(glob.glob('../input/ph2-resized/trainy/*.bmp'), key=numericalSort)\n",
    "Y_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:18:59.066998Z",
     "iopub.status.busy": "2022-04-11T06:18:59.066715Z",
     "iopub.status.idle": "2022-04-11T06:18:59.096287Z",
     "shell.execute_reply": "2022-04-11T06:18:59.095529Z",
     "shell.execute_reply.started": "2022-04-11T06:18:59.066947Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:02.547574Z",
     "iopub.status.busy": "2022-04-11T06:19:02.547248Z",
     "iopub.status.idle": "2022-04-11T06:19:04.121026Z",
     "shell.execute_reply": "2022-04-11T06:19:04.120302Z",
     "shell.execute_reply.started": "2022-04-11T06:19:02.547519Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(X_train[0])\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(X_train[3])\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(X_train[54])\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(X_train[77])\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow(X_train[100])\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow(X_train[125])\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(X_train[130])\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(X_train[149])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:08.251338Z",
     "iopub.status.busy": "2022-04-11T06:19:08.251007Z",
     "iopub.status.idle": "2022-04-11T06:19:09.754534Z",
     "shell.execute_reply": "2022-04-11T06:19:09.753759Z",
     "shell.execute_reply.started": "2022-04-11T06:19:08.251282Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(Y_train[0], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(Y_train[3], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(Y_train[54], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(Y_train[77], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow(Y_train[100], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow(Y_train[125], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(Y_train[130], cmap = plt.cm.binary_r)\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(Y_train[149], cmap = plt.cm.binary_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:13.435198Z",
     "iopub.status.busy": "2022-04-11T06:19:13.434875Z",
     "iopub.status.idle": "2022-04-11T06:19:13.441071Z",
     "shell.execute_reply": "2022-04-11T06:19:13.440278Z",
     "shell.execute_reply.started": "2022-04-11T06:19:13.43514Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:16.059164Z",
     "iopub.status.busy": "2022-04-11T06:19:16.058843Z",
     "iopub.status.idle": "2022-04-11T06:19:16.065502Z",
     "shell.execute_reply": "2022-04-11T06:19:16.064264Z",
     "shell.execute_reply.started": "2022-04-11T06:19:16.059101Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth = 100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:18.259189Z",
     "iopub.status.busy": "2022-04-11T06:19:18.258875Z",
     "iopub.status.idle": "2022-04-11T06:19:18.264942Z",
     "shell.execute_reply": "2022-04-11T06:19:18.263707Z",
     "shell.execute_reply.started": "2022-04-11T06:19:18.259137Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coe(y_true, y_pred, smooth = 100):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:20.876881Z",
     "iopub.status.busy": "2022-04-11T06:19:20.876593Z",
     "iopub.status.idle": "2022-04-11T06:19:20.883449Z",
     "shell.execute_reply": "2022-04-11T06:19:20.882591Z",
     "shell.execute_reply.started": "2022-04-11T06:19:20.876831Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:23.658864Z",
     "iopub.status.busy": "2022-04-11T06:19:23.658444Z",
     "iopub.status.idle": "2022-04-11T06:19:23.664487Z",
     "shell.execute_reply": "2022-04-11T06:19:23.663546Z",
     "shell.execute_reply.started": "2022-04-11T06:19:23.658798Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:26.434956Z",
     "iopub.status.busy": "2022-04-11T06:19:26.434639Z",
     "iopub.status.idle": "2022-04-11T06:19:26.439616Z",
     "shell.execute_reply": "2022-04-11T06:19:26.438861Z",
     "shell.execute_reply.started": "2022-04-11T06:19:26.434896Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Calculates the mean accuracy rate across all predictions for binary\n",
    "    classification problems.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:30.418083Z",
     "iopub.status.busy": "2022-04-11T06:19:30.417776Z",
     "iopub.status.idle": "2022-04-11T06:19:30.42661Z",
     "shell.execute_reply": "2022-04-11T06:19:30.425805Z",
     "shell.execute_reply.started": "2022-04-11T06:19:30.418023Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(x_image, y_image):\n",
    "    rows_x,cols_x, chl_x = x_image.shape\n",
    "    rows_y,cols_y = y_image.shape\n",
    "    rand_num = np.random.randint(-40,40)\n",
    "    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n",
    "    return x_image, y_image.astype('int')\n",
    "\n",
    "def horizontal_flip(x_image, y_image):\n",
    "    x_image = cv2.flip(x_image, 1)\n",
    "    y_image = cv2.flip(y_image.astype('float32'), 1)\n",
    "    return x_image, y_image.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:33.018977Z",
     "iopub.status.busy": "2022-04-11T06:19:33.018692Z",
     "iopub.status.idle": "2022-04-11T06:19:33.026398Z",
     "shell.execute_reply": "2022-04-11T06:19:33.025492Z",
     "shell.execute_reply.started": "2022-04-11T06:19:33.018927Z"
    }
   },
   "outputs": [],
   "source": [
    "def img_augmentation(x_train, y_train):\n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    for idx in range(len(x_train)):\n",
    "        x,y = random_rotation(x_train[idx], y_train[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        x,y = horizontal_flip(x_train[idx], y_train[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:35.706897Z",
     "iopub.status.busy": "2022-04-11T06:19:35.706581Z",
     "iopub.status.idle": "2022-04-11T06:19:36.08163Z",
     "shell.execute_reply": "2022-04-11T06:19:36.080898Z",
     "shell.execute_reply.started": "2022-04-11T06:19:35.706842Z"
    }
   },
   "outputs": [],
   "source": [
    "x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:38.691058Z",
     "iopub.status.busy": "2022-04-11T06:19:38.690773Z",
     "iopub.status.idle": "2022-04-11T06:19:39.731897Z",
     "shell.execute_reply": "2022-04-11T06:19:39.731054Z",
     "shell.execute_reply.started": "2022-04-11T06:19:38.691008Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 7\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(x_train[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(y_train[img_num], plt.cm.binary_r)\n",
    "plt.title('Original Mask')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(x_rotated[img_num])\n",
    "plt.title('Rotated Image')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(y_rotated[img_num], plt.cm.binary_r)\n",
    "plt.title('Rotated Mask')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(x_flipped[img_num])\n",
    "plt.title('Flipped Image')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(y_flipped[img_num], plt.cm.binary_r)\n",
    "plt.title('Flipped Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:46.915279Z",
     "iopub.status.busy": "2022-04-11T06:19:46.914832Z",
     "iopub.status.idle": "2022-04-11T06:19:47.067668Z",
     "shell.execute_reply": "2022-04-11T06:19:47.066874Z",
     "shell.execute_reply.started": "2022-04-11T06:19:46.915074Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "y_train_full = np.concatenate([y_train, y_rotated, y_flipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:49.618926Z",
     "iopub.status.busy": "2022-04-11T06:19:49.618644Z",
     "iopub.status.idle": "2022-04-11T06:19:49.767188Z",
     "shell.execute_reply": "2022-04-11T06:19:49.766399Z",
     "shell.execute_reply.started": "2022-04-11T06:19:49.618875Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:52.396273Z",
     "iopub.status.busy": "2022-04-11T06:19:52.395834Z",
     "iopub.status.idle": "2022-04-11T06:19:52.402757Z",
     "shell.execute_reply": "2022-04-11T06:19:52.401855Z",
     "shell.execute_reply.started": "2022-04-11T06:19:52.396069Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Length of the Training Set   : {}\".format(len(x_train)))\n",
    "print(\"Length of the Test Set       : {}\".format(len(x_test)))\n",
    "print(\"Length of the Validation Set : {}\".format(len(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:19:55.787203Z",
     "iopub.status.busy": "2022-04-11T06:19:55.786852Z",
     "iopub.status.idle": "2022-04-11T06:19:55.791738Z",
     "shell.execute_reply": "2022-04-11T06:19:55.790192Z",
     "shell.execute_reply.started": "2022-04-11T06:19:55.787118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n",
    "INPUT_CHANNELS = 3\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "# Pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:33:45.176068Z",
     "iopub.status.busy": "2022-04-11T06:33:45.175778Z",
     "iopub.status.idle": "2022-04-11T06:33:45.181129Z",
     "shell.execute_reply": "2022-04-11T06:33:45.180326Z",
     "shell.execute_reply.started": "2022-04-11T06:33:45.176017Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:20:02.223968Z",
     "iopub.status.busy": "2022-04-11T06:20:02.223686Z",
     "iopub.status.idle": "2022-04-11T06:20:02.245867Z",
     "shell.execute_reply": "2022-04-11T06:20:02.244835Z",
     "shell.execute_reply.started": "2022-04-11T06:20:02.223917Z"
    }
   },
   "outputs": [],
   "source": [
    "def double_conv_layer(x, size, dropout=0.40, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def UNET_224(epochs_num, savename):\n",
    "    dropout_val=0.50\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        inputs = Input((INPUT_CHANNELS, 192, 256))\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((192, 256, INPUT_CHANNELS))\n",
    "        axis = 3\n",
    "    filters = 32\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n",
    "    conv_final = Activation('sigmoid')(conv_final)\n",
    "    pred = Reshape((192,256))(conv_final)\n",
    "    model = Model(inputs, pred, name=\"UNET_224\")\n",
    "    model.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n",
    "                  , metrics=[iou, dice_coe, precision, recall, accuracy])\n",
    "    model.summary()\n",
    "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18,validation_data=(x_val, y_val))\n",
    "    model.save(savename)\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:11:16.719348Z",
     "iopub.status.busy": "2022-04-11T06:11:16.718976Z",
     "iopub.status.idle": "2022-04-11T06:11:16.865611Z",
     "shell.execute_reply": "2022-04-11T06:11:16.863108Z",
     "shell.execute_reply.started": "2022-04-11T06:11:16.719297Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T06:20:07.474957Z",
     "iopub.status.busy": "2022-04-11T06:20:07.47466Z",
     "iopub.status.idle": "2022-04-11T06:20:36.168278Z",
     "shell.execute_reply": "2022-04-11T06:20:36.167526Z",
     "shell.execute_reply.started": "2022-04-11T06:20:07.474903Z"
    }
   },
   "outputs": [],
   "source": [
    "model, hist = UNET_224(1, 'unet_1_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.693563Z",
     "iopub.status.idle": "2022-04-09T11:40:44.694149Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout_val=0.50\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    inputs = Input((INPUT_CHANNELS, 192, 256))\n",
    "    axis = 1\n",
    "else:\n",
    "    inputs = Input((192, 256, INPUT_CHANNELS))\n",
    "    axis = 3\n",
    "filters = 32\n",
    "\n",
    "conv_224 = double_conv_layer(inputs, filters)\n",
    "pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n",
    "conv_final = Activation('sigmoid')(conv_final)\n",
    "pred = Reshape((192,256))(conv_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.695215Z",
     "iopub.status.idle": "2022-04-09T11:40:44.695829Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0 = Model(inputs, pred, name=\"UNET_224\")\n",
    "model_0.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n",
    "                  , metrics=[iou, dice_coe, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.696896Z",
     "iopub.status.idle": "2022-04-09T11:40:44.697481Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0.load_weights('unet_1_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.698554Z",
     "iopub.status.idle": "2022-04-09T11:40:44.699145Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n~~~~~~~~~~~~~~~Stats after 1 epoch~~~~~~~~~~~~~~~~~~~')\n",
    "print('\\n-------------On Train Set--------------------------\\n')\n",
    "res = model_0.evaluate(x_train, y_train, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On Test  Set--------------------------\\n')\n",
    "res = model_0.evaluate(x_test, y_test, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On validation Set---------------------\\n')\n",
    "res = model_0.evaluate(x_val, y_val, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.700193Z",
     "iopub.status.idle": "2022-04-09T11:40:44.700795Z"
    }
   },
   "outputs": [],
   "source": [
    "model, hist = UNET_224(epochs_num= 100, savename= 'unet_100_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.701845Z",
     "iopub.status.idle": "2022-04-09T11:40:44.70243Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = Model(inputs, pred, name=\"UNET_224\")\n",
    "model_1.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n",
    "                  , metrics=[iou, dice_coe, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.703476Z",
     "iopub.status.idle": "2022-04-09T11:40:44.704058Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1.load_weights('unet_100_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.705135Z",
     "iopub.status.idle": "2022-04-09T11:40:44.705737Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\n",
    "print('\\n-------------On Train Set--------------------------\\n')\n",
    "res = model_1.evaluate(x_train, y_train, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On Test  Set--------------------------\\n')\n",
    "res = model_1.evaluate(x_test, y_test, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')\n",
    "print('\\n-------------On validation Set---------------------\\n')\n",
    "res = model_1.evaluate(x_val, y_val, batch_size= 18)\n",
    "print('________________________')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.706792Z",
     "iopub.status.idle": "2022-04-09T11:40:44.70736Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14))\n",
    "plt.suptitle('Training Statistics on Train Set')\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(hist.history['loss'], 'red')\n",
    "plt.title('Loss')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(hist.history['accuracy'], 'green')\n",
    "plt.title('Accuracy')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(hist.history['val_loss'], 'red')\n",
    "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
    "plt.title('Valdiation Loss')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(hist.history['val_accuracy'], 'green')\n",
    "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
    "plt.title('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.708429Z",
     "iopub.status.idle": "2022-04-09T11:40:44.70902Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 49\n",
    "img_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x_test[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(y_test[img_num], plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\n",
    "plt.title('Predicted Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.710075Z",
     "iopub.status.idle": "2022-04-09T11:40:44.710675Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 10\n",
    "img_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x_test[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(y_test[img_num], plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_pred.reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.711737Z",
     "iopub.status.idle": "2022-04-09T11:40:44.712313Z"
    }
   },
   "outputs": [],
   "source": [
    "img_num = 36\n",
    "img_pred = model_1.predict(x_test[img_num].reshape(1,192,256,3))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x_test[img_num])\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(y_test[img_num], plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_pred.reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.713368Z",
     "iopub.status.idle": "2022-04-09T11:40:44.713962Z"
    }
   },
   "outputs": [],
   "source": [
    "def enhance(img):\n",
    "    sub = (model_1.predict(img.reshape(1,224,224,3))).flatten()\n",
    "\n",
    "    for i in range(len(sub)):\n",
    "        if sub[i] > 0.5:\n",
    "            sub[i] = 1\n",
    "        else:\n",
    "            sub[i] = 0\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-09T11:40:44.715008Z",
     "iopub.status.idle": "2022-04-09T11:40:44.715629Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.suptitle('Comparing the Prediction after enhancement')\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(y_test[21],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(y_test[47],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(enhance(x_test[47]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(y_test[36],plt.cm.binary_r)\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(enhance(x_test[36]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
